{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to revisit your classifier from the previous assignment. Using the evaluation techniques we've covered here, look at your classifier's performance in more detail. Then go back and iterate by engineering new features, removing poor features, or tuning parameters. Repeat this process until you have five different versions of your classifier. Once you've iterated, answer these questions to compare the performance of each:\n",
    "\n",
    "- Do any of your classifiers seem to overfit? <br>\n",
    "- Which seem to perform the best? Why? <br>\n",
    "- Which features seemed to be most impactful to performance? <br>\n",
    "\n",
    "\n",
    "Write up your iterations and answers to the above questions in a few pages. Submit a link below and go over it with your mentor to see if they have any other ideas on how you could improve your classifier's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text data from Amazon\n",
    "df=pd.read_csv('sentiment labelled sentences/amazon_cells_labelled.txt', sep= '\\t',header=None)\n",
    "df.columns=['text','senti']\n",
    "\n",
    "\n",
    "# The positive key words were obtained from https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html#datasets\n",
    "\n",
    "keyword_pos=pd.read_csv('opinion-lexicon-English/positive-words.txt',sep='\\t',header=None,skiprows=31)\n",
    "keyword_pos=keyword_pos[0].tolist()\n",
    "\n",
    "for key in keyword_pos:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    df[str(key)] = df.text.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.665\n",
      "Testing on Sample: 0.729\n"
     ]
    }
   ],
   "source": [
    "# Test your model with different holdout groups.\n",
    "data=df[keyword_pos]\n",
    "target=df['senti']\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.665\n",
      "Testing on Sample: 0.729\n"
     ]
    }
   ],
   "source": [
    "# Holdout groups\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7 , 0.67, 0.69, 0.68, 0.72, 0.64, 0.71, 0.65, 0.7 , 0.65])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, data, target, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[92,  3],\n",
       "       [64, 41]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true=y_test\n",
    "y_pred=bnb.fit(X_train, y_train).predict(X_test)\n",
    "confusion_matrix(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
